Python script for HTTP scraping 
```python
!/bin/env python
import requests
from bs4 import BeautifulSoup
import urllib

r = urllib.urlopen('')
soup = BeautifulSoup(r,"lxml")
print type(soup)
print soup.prettify()

```

```{r, engine='bash', count_lines}
#!/bin/sh

echo "Filtering.............."
python test.py 2>&1 | grep ^URL |cut -d' ' -f2  >> result.txt 
cat result.txt | grep -vE "fxf|dat" >> result.txt
```

Python script for HTTP scraping 
```python
#!/bin/usr/env python
from bs4 import BeautifulSoup
import urllib
import re
urlss = ""

def scrape(input):
	print "Scrapping current site \n"
	print input
	print "\n\n"
	r = urllib.urlopen(input).read()
	soup = BeautifulSoup(r,"lxml")

  	output = soup.prettify()
  	urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', output)
  	#print urls

  	for url in urls:
		print url

if __name__ == '__main__':
    print "Scrapping"
    scrape('http://github.com')

```
